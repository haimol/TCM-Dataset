# TCM Question Database

A comprehensive Traditional Chinese Medicine (TCM) question dataset containing both extracted and AI-generated multiple-choice questions for medical education and research.

## ğŸ“Š Dataset Overview

**Total Questions: 13,750**
- **Extracted Data:** 11,349 questions (original sources)
- **Generated Data:** 2,401 questions (AI-generated using TCM-Align)

## ğŸ“ Repository Structure

```
TCM-DATA/
â”œâ”€â”€ Extracted-Data/          # Original question collections
â”‚   â”œâ”€â”€ ä¸­åŒ»å†…ç§‘å­¦/           # TCM Internal Medicine (897 questions)
â”‚   â”œâ”€â”€ ä¸­åŒ»å¤–ç§‘å­¦/           # TCM Surgery (899 questions)  
â”‚   â”œâ”€â”€ ä¸­åŒ»å¦‡ç§‘å­¦/           # TCM Gynecology (899 questions)
â”‚   â”œâ”€â”€ ä¸­åŒ»å„¿ç§‘å­¦/           # TCM Pediatrics (500 questions)
â”‚   â”œâ”€â”€ questions.json      # Consolidated questions (325 questions)
â”‚   â”œâ”€â”€ ä¸­åŒ»ä½åŸ¹é¢˜.json      # Resident physician training questions (7,829 questions)
â”‚   â””â”€â”€ *-metadata.json     # Metadata files documenting structure
â””â”€â”€ Generated-Data/          # AI-generated using TCM-Align methodology
    â”œâ”€â”€ å®ç”¨ä¸­åŒ»å†…ç§‘å­¦.json    # Practical TCM Internal Medicine (694 questions)
    â”œâ”€â”€ ä¸­åŒ»åŸºç¡€ç†è®º.json      # TCM Basic Theory (374 questions)
    â”œâ”€â”€ ä¸­åŒ»å¦‡ç§‘å­¦.json        # TCM Gynecology (378 questions)
    â”œâ”€â”€ ä¸­åŒ»è¯Šæ–­å­¦.json        # TCM Diagnostics (320 questions)
    â”œâ”€â”€ ä¸­åŒ»å„¿ç§‘å­¦.json        # TCM Pediatrics (281 questions)
    â”œâ”€â”€ ä¸­åŒ»çœ¼ç§‘å­¦.json        # TCM Ophthalmology (210 questions)
    â””â”€â”€ ä¸­åŒ»å¤–ç§‘å­¦.json        # TCM Surgery (144 questions)
```

## ğŸ—‚ï¸ Data Categories

### Extracted Data (11,349 questions)

Original questions collected from various TCM educational sources:

| Category | A1-Type Questions | A2-Type Questions | Total |
|----------|------------------|------------------|-------|
| ä¸­åŒ»å†…ç§‘å­¦ (TCM Internal Medicine) | 600 | 297 | 897 |
| ä¸­åŒ»å¤–ç§‘å­¦ (TCM Surgery) | 599 | 300 | 899 |
| ä¸­åŒ»å¦‡ç§‘å­¦ (TCM Gynecology) | 599 | 300 | 899 |
| ä¸­åŒ»å„¿ç§‘å­¦ (TCM Pediatrics) | 300 | 200 | 500 |
| **Additional Sources** | | | **8,154** |
| ä½åŸ¹é¢˜ (Resident Physician Training) | - | - | 7,829 |
| General Questions | - | - | 325 |

**Question Types:**
- **A1-Type**: Single best answer multiple choice (direct knowledge recall)
- **A2-Type**: Case-based clinical scenario questions (application of knowledge)

### Generated Data (2,401 questions)

AI-generated questions using the **TCM-Align** methodology across 7 core TCM domains:

| Domain | Questions | Description |
|--------|-----------|-------------|
| å®ç”¨ä¸­åŒ»å†…ç§‘å­¦ | 694 | Practical TCM Internal Medicine |
| ä¸­åŒ»å¦‡ç§‘å­¦ | 378 | TCM Gynecology |
| ä¸­åŒ»åŸºç¡€ç†è®º | 374 | TCM Basic Theory |
| ä¸­åŒ»è¯Šæ–­å­¦ | 320 | TCM Diagnostics |
| ä¸­åŒ»å„¿ç§‘å­¦ | 281 | TCM Pediatrics |
| ä¸­åŒ»çœ¼ç§‘å­¦ | 210 | TCM Ophthalmology |
| ä¸­åŒ»å¤–ç§‘å­¦ | 144 | TCM Surgery |

## ğŸ¤– TCM-Align Methodology

The Generated-Data was created using **TCM-Align**, a novel framework for curriculum-aligned MCQ generation published at UbiComp Companion '25.

### Key Features

1. **Heuristic-based Knowledge Extraction**
   - Parses TCM textbooks along chapter/section boundaries
   - Maintains semantic coherence within question topics

2. **Dual-Summary Semantic Filtering**
   - Generates two independent summaries per text segment
   - Applies cosine similarity threshold (â‰¥0.92) for quality control
   - Filters out hallucinated or low-confidence content

3. **MCQ Generator with Format Verification**
   - Creates structured multiple-choice questions with explanations
   - Ensures one correct answer and three plausible distractors
   - Maintains factual consistency with source material

### Quality Metrics

The TCM-Align framework achieves:
- **Source-Consistency Accuracy (SCA)**: 0.98 (98% factual accuracy)
- **94.3% improvement** in Explanation Richness vs. baseline methods
- **>10% gains** in most quality metrics including reasoning depth and distractor quality

### Source Materials

Generated from **Chinese National TCM Higher-Education Planned Textbooks series**, including:
- TCM Basic Theory
- TCM Diagnostics  
- TCM Internal Medicine
- TCM Surgery
- TCM Gynecology
- TCM Pediatrics
- TCM Ophthalmology

## ğŸ“‹ Data Format

### Extracted Data Format
```json
{
    "query": "æ‚£è€…ç‹æŸï¼Œç”·æ€§ï¼Œ69å²ã€‚å¤§ä¾¿è‰°æ¶©...",
    "choices": [
        "æ°”ç§˜",
        "å†·ç§˜", 
        "çƒ­ç§˜",
        "è™šç§˜",
        "å®ç§˜"
    ],
    "answers": ["è™šç§˜"],
    "explanation": ""
}
```

### Generated Data Format (Enhanced)
```json
{
    "item_id": "å®ç”¨ä¸­åŒ»å†…ç§‘å­¦å®Œæ•´-0",
    "generated_question": {
        "question": "ã€Šå†…ç»ã€‹å¯¹ä¸­åŒ»å†…ç§‘å­¦çš„è´¡çŒ®ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å“ªä¸€é¡¹ï¼Ÿ",
        "options": [
            {
                "label": "A",
                "text": "åˆ›ç«‹äº†è„è…‘ã€ç»ç»œã€æ°”è¡€ä½“ç³»ï¼Œæå‡ºç—…å› ç—…æœºå­¦è¯´",
                "correct": true
            },
            {
                "label": "B", 
                "text": "é¦–æ¬¡è®°è½½ç‹‚çŠ¬ç—…çš„ä¼ æ’­ä¸é¢„é˜²æ–¹æ³•",
                "correct": false
            }
        ],
        "explanation": "ã€Šå†…ç»ã€‹å¥ å®šäº†ä¸­åŒ»å†…ç§‘å­¦çš„ç†è®ºåŸºç¡€..."
    }
}
```

## ğŸ¯ Use Cases

### Educational Applications
- **Medical School Training**: Comprehensive question banks for TCM curricula
- **Licensing Exam Preparation**: Practice questions for TCM certification
- **Continuing Education**: Professional development for TCM practitioners

### Research Applications  
- **NLP Model Training**: Large-scale domain-specific dataset for Chinese medical NLP
- **Question Generation Research**: Benchmark for automated MCQ generation
- **Educational Assessment**: Evaluation of TCM knowledge and reasoning

### Clinical Applications
- **Knowledge Assessment**: Evaluate TCM practitioners' competency
- **Diagnostic Training**: Case-based reasoning for clinical scenarios

## ğŸ“ˆ Dataset Statistics

| Metric | Extracted Data | Generated Data | Total |
|--------|---------------|---------------|-------|
| **Total Questions** | 11,349 | 2,401 | **13,750** |
| **Average Explanation Length** | Minimal | Rich & Detailed | - |
| **Question Types** | A1/A2 Mixed | MCQ with Explanations | - |
| **Domains Covered** | 4 Main + Others | 7 Core Domains | 8+ |
| **Quality Assurance** | Manual Collection | AI-Filtered (SCA=0.98) | - |

## ğŸ”§ Getting Started

### Loading the Data

**Python Example:**
```python
import json

# Load extracted data
with open('Extracted-Data/1ã€ä¸­åŒ»å†…ç§‘å­¦600é“A1å‹é¢˜.json', 'r', encoding='utf-8') as f:
    extracted_questions = json.load(f)

# Load generated data  
with open('Generated-Data/å®ç”¨ä¸­åŒ»å†…ç§‘å­¦.json', 'r', encoding='utf-8') as f:
    generated_questions = json.load(f)

print(f"Extracted: {len(extracted_questions)} questions")
print(f"Generated: {len(generated_questions)} questions")
```

### Question Count Script
```bash
python count_questions.py
```
Generates `question_count_summary.txt` with detailed statistics.

## ğŸ“š Citation

If you use this dataset in your research, please cite:

```bibtex
@inproceedings{lu2025tcmalign,
  title={TCM-Align: Curriculum-Aligned MCQ Generation for Traditional Chinese Medicine},
  author={Lu, Haimo and Liu, Li and Yuan, Jinliang and Zheng, Yawen and Wang, Zhenyu and Liu, Kebin},
  booktitle={Companion of the 2025 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
  pages={1--6},
  year={2025},
  organization={ACM}
}
```

## ğŸ“„ License

This work is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).

## ğŸ¤ Contributing

We welcome contributions to expand and improve this dataset:

1. **Additional Question Sources**: Submit new TCM questions with proper attribution
2. **Quality Improvements**: Report issues or suggest enhancements
3. **Translation**: Help translate questions to other languages
4. **Evaluation**: Provide feedback on question quality and difficulty

## ğŸ“ Contact

For questions, suggestions, or collaboration opportunities:

- **Primary Contact**: Li Liu (liuli95@mail.tsinghua.edu.cn)
- **Lead Author**: Haimo Lu (haimolu@live.com)
- **Institution**: Tsinghua University, Beijing, China

## ğŸ”— Related Work

### TCM-Specific Datasets
- **TCM-QA** [9]: 574 questions extracted from BaiduWenKu for ChatGPT evaluation
- **TCMBench** [7]: 5,473 questions from TCM licensing exams for LLM benchmarking  
- **TCMD** [8]: 3,451 TCM QA pairs for large language model evaluation
- **Huatuo-26M** [12]: Large-scale Chinese medical QA dataset with 26M pairs
- **CMExam** [13]: 60,000+ questions from Chinese National Medical Licensing Examination

### LLM-Based Question Generation
- **SciQAG** [10]: Framework for auto-generated science QA datasets with fine-grained evaluation
- **MCQGen** [14]: LLM-driven MCQ generator using retrieval-augmented generation
- **EHR-DS-QA** [11]: Synthetic QA dataset from medical discharge summaries

### TCM-Specific Language Models
- **Qibo** [5]: Large language model specialized for Traditional Chinese Medicine
- **Zhongjing** [6]: Enhanced Chinese medical LLM with expert feedback and dialogue

### Foundational Technologies
- **GPT-4** [3]: Advanced language model used in our TCM-Align pipeline
- **Sentence-BERT** [21]: Sentence embeddings for semantic similarity computation
- **Self-Consistency** [22]: Chain of thought reasoning methodology applied in our dual-summary filtering

## âš ï¸ Important Notes

1. **Educational Purpose**: This dataset is intended for educational and research use only
2. **Medical Disclaimer**: Not for clinical decision-making or patient care
3. **Quality Assurance**: Generated questions achieve 98% factual consistency but should be reviewed by domain experts for clinical applications
4. **Language**: Primarily in Chinese (Simplified), reflecting the source materials and target audience

## ğŸ“– References

[3] Josh Achiam, Steven Adler, Sandhini Agarwal, et al. GPT-4 technical report. *arXiv preprint arXiv:2303.08774*, 2023.

[5] Heyi Zhang, Xin Wang, Zhaopeng Meng, Zhe Chen, Pengwei Zhuang, Yongzhe Jia, Dawei Xu, and Wenbin Guo. Qibo: A large language model for traditional chinese medicine. 2024.

[6] Songhua Yang, Hanjie Zhao, Senbin Zhu, Guangyu Zhou, Hongfei Xu, Yuxiang Jia, and Hongying Zan. Zhongjing: Enhancing the chinese medical capabilities of large language model through expert feedback and real-world multi-turn dialogue. 2023.

[7] Wenjing Yue, Xiaoling Wang, Wei Zhu, Ming Guan, Huanran Zheng, Pengfei Wang, Changzhi Sun, and Xin Ma. TCMBench: A comprehensive benchmark for evaluating large language models in traditional chinese medicine. 2024.

[8] Ping Yu, Kaitao Song, Fengchen He, Ming Chen, and Jianfeng Lu. TCMD: A traditional chinese medicine qa dataset for evaluating large language models. *arXiv preprint arXiv:2406.04941*, 2024.

[9] Li Yizhen, Huang Shaohan, Qi Jiaxing, Quan Lei, Han Dongran, and Luan Zhongzhi. Exploring the comprehension of ChatGPT in traditional chinese medicine knowledge. 2024.

[10] Yuwei Wan, Yixuan Liu, Aswathy Ajith, Clara Grazian, Bram Hoex, Wenjie Zhang, Chunyu Kit, Tong Xie, and Ian Foster. SciQAG: A framework for auto-generated science question answering dataset with fine-grained evaluation. 2024.

[11] Konstantin Kotschenreuther. EHR-DS-QA: A synthetic QA dataset derived from medical discharge summaries for enhanced medical information retrieval systems. 2024.

[12] Jianquan Li, Xidong Wang, Xiangbo Wu, Zhiyi Zhang, Xiaolong Xu, Jie Fu, Prayag Tiwari, Xiang Wan, and Benyou Wang. Huatuo-26M, a large-scale chinese medical QA dataset. 2023.

[13] Junling Liu, Peilin Zhou, Yining Hua, Dading Chong, Zhongyu Tian, Andrew Liu, Helin Wang, Chenyu You, Zhenhua Guo, Lei Zhu, and Michael Lingzhi Li. Benchmarking large language models on CMExam â€“ a comprehensive chinese medical exam dataset. 2023.

[14] Ching Nam Hang, Chee Wei Tan, and Pei-Duo Yu. MCQGen: A large language model-driven MCQ generator for personalized learning. *IEEE Access*, 12:102261â€“102273, 2024.

[21] Nils Reimers and Iryna Gurevych. Sentence-BERT: Sentence embeddings using siamese BERT-networks. In *Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing*. Association for Computational Linguistics, November 2019.

[22] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Nathan Scales, et al. Self-consistency improves chain of thought reasoning in language models. In *Advances in Neural Information Processing Systems (NeurIPS)*, 2023.

---

**Last Updated**: December 2024  
**Dataset Version**: 1.0  
**Total Size**: ~15MB (JSON format) 